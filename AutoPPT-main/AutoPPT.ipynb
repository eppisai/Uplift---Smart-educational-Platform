{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web scraping, pptx, requests imports                                                                                     @****\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pptx.util import Inches, Pt\n",
    "from pptx import Presentation\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "#import wikipedia (this can also be done to directly use functions for user-friendly scraping but it is \n",
    "# noticably sytlow) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the topic !? :)roses\n",
      "what's your name?\n"
     ]
    }
   ],
   "source": [
    "topic= input(\"what is the topic !? :)\")                                                                                #@****\n",
    "user=input(\"what's your name?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line uses 'get' function to make a response object and to get the source code , use .text @***\n",
    "try:\n",
    "    source=requests.get('https://en.wikipedia.org/wiki/'+ topic).text\n",
    "except:\n",
    "    print(\"Error opening the URL\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup= BeautifulSoup(source , 'lxml')\n",
    "# the next line gives the entire source code                                                                          @****\n",
    "#print(soup.prettify()) <--------------this is source code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one seperate soup of headings as well as paragraphs, this helps in targeting the topics individually, later.\n",
    "article=\" \"\n",
    "for heading in soup.find_all([\"p\", \"h2\", \"h3\"]):\n",
    "    article += heading.name + ' ' + heading.text.strip()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#..                                                                                                                     ****\n",
    "first_slide= \"\"\n",
    "second_slide= \"\"\n",
    "third_slide= \"\"\n",
    "fourth_slide= \"\"\n",
    "fifth_slide= \"\"\n",
    "sixth_slide= \"\"\n",
    "seventh_slide= \"\"\n",
    "matter =''\n",
    "deffi_slides=[]\n",
    "count=0\n",
    "lines=0\n",
    "'''\n",
    "this piece of code is specific to wikipidea.\n",
    "every page has its last hyperlinked heading as \"see also\" and we dont want it.\n",
    "also, the index was too big to fit into one slide, so i split the entries in more slides.the \"if\" section is for that slpitting.\n",
    "below it, we have 4 lines of code which extract out the first line of each heading by finding  the first full stop available.\n",
    "'''\n",
    "for heading in soup.find_all([ \"h2\", \"h3\"]):\n",
    "    if heading.text.strip()=='See also':\n",
    "            break\n",
    "    if heading.name== \"h2\":\n",
    "        char= ' ' + heading.text.strip()+\"\\n\"\n",
    "    if heading.name == \"h3\":\n",
    "        char = '  -- ' + heading.text.strip()+ \"\\n\"\n",
    "    lines+=1\n",
    "    matter= ''\n",
    "          #-----------------divides the *contents* section into parts of 9 lines per slide. to avoid congession\n",
    "\n",
    "    \n",
    "    if  lines<=9 and  (not char.isdigit()):\n",
    "        first_slide=first_slide+char\n",
    "        count=1\n",
    "    if  lines>9 and lines<+18 :\n",
    "        second_slide=second_slide+char\n",
    "        count=2\n",
    "    if lines>18 and lines<=27   :\n",
    "        third_slide=third_slide+char\n",
    "        count=3\n",
    "    if lines>27 and lines<=36 :\n",
    "        fourth_slide=fourth_slide+char\n",
    "        count=4\n",
    "    if lines>36 and  lines<=45 :\n",
    "        fifth_slide=fifth_slide+char\n",
    "        count=5\n",
    "    if lines>45 and  lines<=54 :\n",
    "        sixth_slide=sixth_slide+char\n",
    "        count=6    \n",
    "    if lines>54 and  lines<=63 :\n",
    "        seventh_slide=seventh_slide+char\n",
    "        count=7\n",
    "        #----------------------------------- finding the first sentences---------------\n",
    "    start_def = article.find(heading.text.strip()) \n",
    "    end_def= article.find('.',start_def)\n",
    "    matter += article[start_def: end_def+1]    \n",
    "    deffi_slides= deffi_slides +[[str(heading.text.strip()), str(matter), 1]]   \n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rose', ' by python for :)', 0]\n",
      "['contents', ' Contents\\n Etymology\\n Botany\\n  -- Species\\n Uses\\n  -- Ornamental plants\\n  -- Cut flowers\\n  -- Perfume\\n  -- Food and drink\\n', 1]\n",
      "['contents', '  -- Medicine\\n  -- Art and symbolism\\n Pests and diseases\\n', 1]\n",
      "['Contents', 'Contentsh2 Etymologyp The name rose comes from French, itself from Latin rosa, which was perhaps borrowed from Oscan, from Greek ρόδον rhódon (Aeolic βρόδον wródon), itself borrowed from Old Persian wrd- (wurdi), related to Avestan varəδa, Sogdian ward, Parthian wâr.', 1]\n",
      "['Etymology', 'Etymologyp The name rose comes from French, itself from Latin rosa, which was perhaps borrowed from Oscan, from Greek ρόδον rhódon (Aeolic βρόδον wródon), itself borrowed from Old Persian wrd- (wurdi), related to Avestan varəδa, Sogdian ward, Parthian wâr.', 1]\n",
      "['Botany', 'Botanyp The leaves are borne alternately on the stem.', 1]\n",
      "['Species', 'Species, cultivars and hybrids are all widely grown for their beauty and often are fragrant.', 1]\n",
      "['Uses', 'Usesp Roses are best known as ornamental plants grown for their flowers in the garden and sometimes indoors.', 1]\n",
      "['Ornamental plants', 'Ornamental plantsp The majority of ornamental roses are hybrids that were bred for their flowers.', 1]\n",
      "['Cut flowers', 'Cut flowersp Roses are a popular crop for both domestic and commercial cut flowers.', 1]\n",
      "['Perfume', 'Perfumep Rose perfumes are made from rose oil (also called attar of roses), which is a mixture of volatile essential oils obtained by steam distilling the crushed petals of roses.', 1]\n",
      "['Food and drink', 'Food and drinkp Rose hips are occasionally made into jam,  jelly, marmalade, and soup or are brewed for tea, primarily for their high vitamin C content.', 1]\n",
      "['Medicine', 'Medicinep The rose hip, usually from R.', 1]\n",
      "['Art and symbolism', 'Art and symbolismp The long cultural history of the rose has led to it being used often as a symbol.', 1]\n",
      "['Pests and diseases', 'Pests and diseasesp Wild roses are host plants for a number of pests and diseases.', 1]\n"
     ]
    }
   ],
   "source": [
    "prs = Presentation()\n",
    "# the format of this class is to refer to a 'list if lists'(make sure you remember this,or  it can lead to a frustrating mistake).\n",
    "# i found the class format, as the only way to add a second slide.so every required data is put into that format\n",
    "\n",
    "class MySlide:\n",
    "    def __init__(self, data):\n",
    "        self.layout = prs.slide_layouts[data[2]]\n",
    "        #apply the layout to the slide\n",
    "        self.slide = prs.slides.add_slide(self.layout)\n",
    "        self.title = self.slide.shapes.title\n",
    "        self.title.text = data[0]\n",
    "        self.subtitle = self.slide.placeholders[1]\n",
    "        self.subtitle.text=data[1]\n",
    "        \n",
    "slides=[[ soup.h1.text , \" by python for \"+ user+\":)\", 0]]\n",
    "index_slide=[ first_slide , second_slide, third_slide, fourth_slide, fifth_slide, sixth_slide, seventh_slide]\n",
    "indexing = []\n",
    "for a in range (count):\n",
    "    indexing = indexing+[[\"contents\",index_slide[a], 1]]\n",
    "## slides= slides+indexing and so on.... slides should be the final, only list, for easier addition.    \n",
    "\n",
    "    \n",
    "slides= slides+ indexing + deffi_slides\n",
    "\n",
    "for es in slides:\n",
    "    print(es)\n",
    "    MySlide(es)\n",
    "\n",
    "\n",
    "    \n",
    "prs.save('something.pptx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'             this   is  the    end     of   the   working  code   for   a  basic   ppt                             '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''             this   is  the    end     of   the   working  code   for   a  basic   ppt                             '''\n",
    "#-------------------xxxxxxxxxxxxx----------------xxxxxxxxxxxxxxxxxx--------------------xxxxxxxxxxxxxx-------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
